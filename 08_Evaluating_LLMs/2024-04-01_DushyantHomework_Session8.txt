Dushyant (darora_mn) Homework Session#8 Evaluating LLMs and Potential Pitfalls
What do you think is a particularly good use case for LLMs for science? How would you evaluate it? Your answer does not need to be in paragraphs. When you submit your homework form, you can link to a file in your Github repo where you wrote your answer.

Large Language Models (LLMs) form a basis with explicit/implicit statistical/algorithmic, Neural Network (linear and non-linear) , Natural Language Processing (NLP) models supplemented with  multi-modal data as a "platform" that has several applications for every field of Science. In my industry (Ports/terminals/ Logistics), I am utilizing combined simulation (synthetic) and live data sets to generate models for optimization of operations such as predictive analysis on-time of arrival of container vessels, ferry vessels, ro-ro vessels. We combine multi-modal data sets, meteorological (ocean)(short-term and time-series data), tidal, and weather (storm/surge) data combined with vessel data (number of containers, cargo) to predict and analyze the operations, amount of equipment and workforce we expect to manage the vessel and discharge it at the earliest time to continue the shipping cycle in an optimized manner. We plan terminals with a simulation software FlexTerm (https://www.flexterm.com/) that has a statistical engine built inside it to anticipate uncertainties and model and optimized terminal for downtime analysis with "wehat-if" scenarios based on an internall developed LLM model for each new port we plan. We further use Reinforcement Learning (RL) to try to optimize the operational processes by changing parameters with new design technologies such as automation. Consider this as a similar example in the aviation industry where airlines utilize LLM's to predict on-time arrival/departure of passenger airlines in an optimized manner including their on-time arrival of their baggages. For such general use-cases LLM's are appropriate. 
However, I am a bit skeptical on using LLM's for core science use-cases which rely on experimental data unless extremely powerful and verified pre-trained models specifically built for purpose are utilizied and comprehensively tested before releasing/using them for research or commercial use. For example, using pre-trained models from the Chemical industry and applying them for Pharmaceutical industry would be a dangerous overeach. Therefore, LLM's built for specific use-cases trained with appropriate and accurate datasets should be considered carefully otherwise LLM's will provide poor results and eventually fall out of fashion. 
Further, as part of ALCF's Director's Discretionary (DD) allocation offering for public-private initiatives, I have been working with the ALCF team (Murali Emani, Venkat, & David E. Miller) on a proposal to run proprietary LLM's on the AI-Testbeds (particularly SambaNova Systems & Cerebras) in a mutually-beneficial manner. This is a longer-term engagement and will take time to go through the process in a systematic manner. I am working as a industry collaborator with ANL and Pacific Northwest National Lab (PNNL) on various research topics and intend to run some of their LLM's with industry datasets for testing. Only after real-live data can the efficacy of the models be truly adopted in the industry.